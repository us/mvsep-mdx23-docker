{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P22b2fr1q1js"
      },
      "source": [
        "# MVSep-MDX23 Colab Fork v2.5\n",
        "Adaptation of MVSep-MDX23 algorithm for Colab, with few tweaks:\n",
        "\n",
        "https://colab.research.google.com/github/jarredou/MVSEP-MDX23-Colab_v2/blob/v2.4/MVSep-MDX23-Colab.ipynb  \n",
        "<br>  \n",
        "\n",
        "Recent changes:  \n",
        "\n",
        "\n",
        "**v2.5**\n",
        "* Kim's MelBand-Roformer model added  \n",
        "\n",
        "\n",
        "**v2.4**\n",
        "* BS-Roformer models from viperx added\n",
        "* MDX-InstHQ4 model added as optionnal\n",
        "* Flac output\n",
        "* Control input volume gain\n",
        "* Filter vocals below 50Hz option\n",
        "* Better chunking algo (no clicks)\n",
        "* Some code cleaning\n",
        "\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "<details>\n",
        "    <summary>Full changelog :</summary>\n",
        "<br>\n",
        "<font size=2>\n",
        "<br>\n",
        "\n",
        "[**v2.3**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/v2.3)\n",
        "* HQ3-Instr model replaced by VitLarge23 (thanks to MVSep)\n",
        "* Improved MDXv2 processing (thanks to Anjok)\n",
        "* Improved BigShifts algo (v2)\n",
        "* BigShifts processing added to MDXv3 & VitLarge\n",
        "* Faster folder batch processing\n",
        "\n",
        "[**v2.2.2**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/v2.2)\n",
        "* Improved MDXv3 chunking code (thanks to HymnStudio)\n",
        "* D1581 demo model replaced by new InstVocHQ MDXv3 model.\n",
        "<br>\n",
        "\n",
        "**v2.2.1**\n",
        "* Added custom weights feature\n",
        "* Fixed some bugs\n",
        "* Fixed input: you can use a file or a folder as input now\n",
        "<br>\n",
        "\n",
        "**v2.2**\n",
        "* Added MDXv3 compatibility\n",
        "* Added MDXv3 demo model D1581 in vocals stem multiband ensemble.\n",
        "* Added VOC-FT Fullband SRS instead of UVR-MDX-Instr-HQ3.\n",
        "* Added 2stems feature : output only vocals/instrum (faster processing)\n",
        "* Added 16bit output format option\n",
        "* Added \"BigShift trick\" for MDX models\n",
        "* Added separated overlap values for MDX, MDXv3 and Demucs\n",
        "* Fixed volume compensation fine-tuning for MDX-VOC-FT\n",
        "<br>\n",
        "\n",
        "[**v2.1 (by deton24)**](https://github.com/deton24/MVSEP-MDX23-Colab_v2.1)\n",
        "* Updated with MDX-VOC-FT instead of Kim Vocal 2\n",
        "<br>\n",
        "\n",
        "[**v2.0**](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/tree/2.0)\n",
        "* Updated with new Kim Vocal 2 & UVR-MDX-Instr-HQ3 models\n",
        "* Folder batch processing\n",
        "* Fixed high frequency bleed in vocals\n",
        "* Fixed volume compensation for MDX models\n",
        "<br>\n",
        "</font>\n",
        "</details>\n",
        "<br>\n",
        "\n",
        "Credits:\n",
        "* [ZFTurbo/MVSep](https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model)\n",
        "* Models by [Demucs](https://github.com/facebookresearch/demucs), [Anjok](https://github.com/Anjok07/ultimatevocalremovergui), [Kimberley Jensen](https://github.com/KimberleyJensen), [aufr33](https://github.com/aufr33) & viperx\n",
        "* Adaptation & tweaks by [jarredou](https://github.com/jarredou/MVSEP-MDX23-Colab_v2/)\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uWX5WOqjU0QC"
      },
      "outputs": [],
      "source": [
        "#@markdown #Installation\n",
        "#@markdown *Run this cell to install MVSep-MDX23*\n",
        "print('Installing... This will take between 1 and 15 minutes, depending of how crappy Colab currently is...')\n",
        "%cd /content\n",
        "!git clone -b v2.5 https://github.com/jarredou/MVSEP-MDX23-Colab_v2  &> /dev/null\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "print('Installing dependencies...')\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "print('Installation done !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SEYsLSK0xd4-"
      },
      "outputs": [],
      "source": [
        "#@markdown #Gdrive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGXHfn1cq1j4"
      },
      "source": [
        "### About settings:\n",
        "\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **BigShifts :** Better quality/speed performance with values between 3 and 11, **BUT** 11 doesn't always give the best results. Think about it like seed, different values will give slightly different results.<br>\n",
        "Higher values = longer processing.\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Overlap InstVoc/VitLarge :** No big advantage to use high values when BigShifts is already high. If you use BigShifts=1 (regular processing), you can use higher values like 8 or even 16.<br>\n",
        "Higher values = longer processing.<br>\n",
        " *Same goes with overlap_VOCFT, but with values between 0 and 0.95*\n",
        "</font>\n",
        "\n",
        "<font size=2>\n",
        "\n",
        "* **Weights :** How much importance the result from the given model will have in final results.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "V7n1nXKsU4sd"
      },
      "outputs": [],
      "source": [
        "#@markdown #Separation\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "%cd /content/MVSEP-MDX23-Colab_v2\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### separation config:\n",
        "input = '/content/drive/MyDrive/input' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/output' #@param {type:\"string\"}\n",
        "\n",
        "output_format = 'FLAC' #@param [\"PCM_16\", \"FLOAT\", \"FLAC\"]\n",
        "Separation_mode = 'Vocals/Instrumental' #@param [\"Vocals/Instrumental\", \"4-STEMS\"]\n",
        "input_gain = 0 #@param [0, -3, -6] {type:\"raw\"}\n",
        "restore_gain_after_separation = False #@param {type:\"boolean\"}\n",
        "filter_vocals_below_50hz = False #@param {type:\"boolean\"}\n",
        "#@markdown ___\n",
        "##@markdown\n",
        "\n",
        "#@markdown  ### Model config:\n",
        "\n",
        "#@markdown  *Set BigShifts=1 to disable that feature*\n",
        "BigShifts = 3 #@param {type:\"slider\", min:1, max:41, step:1}\n",
        "#@markdown ---\n",
        "BSRoformer_model = 'ep_368_1296' #@param [\"ep_317_1297\", \"ep_368_1296\"]\n",
        "weight_BSRoformer = 9.18 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "weight_Kim_MelRoformer = 10 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "weight_InstVoc = 3.39 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "use_VitLarge = False #@param {type:\"boolean\"}\n",
        "weight_VitLarge = 1 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "#@markdown ---\n",
        "use_InstHQ4 = False #@param {type:\"boolean\"}\n",
        "weight_InstHQ4 = 2 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "overlap_InstHQ4 = 0.1 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "#@markdown ---\n",
        "use_VOCFT = False #@param {type:\"boolean\"}\n",
        "weight_VOCFT = 2 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "overlap_VOCFT = 0.1 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "#@markdown ---\n",
        "#@markdown  *Demucs is only used in 4-STEMS mode.*\n",
        "overlap_demucs = 0.6 #@param {type:\"slider\", min:0, max:0.95, step:0.05}\n",
        "\n",
        "use_InstVoc_ = '--use_InstVoc' #forced use\n",
        "use_BSRoformer_ =  '--use_BSRoformer' #forced use\n",
        "use_Kim_MelRoformer_ =  '--use_Kim_MelRoformer' #forced use\n",
        "\n",
        "use_VOCFT_ = '--use_VOCFT' if use_VOCFT is True else ''\n",
        "use_VitLarge_ = '--use_VitLarge' if use_VitLarge is True else ''\n",
        "use_InstHQ4_ = '--use_InstHQ4' if use_InstHQ4 is True else ''\n",
        "restore_gain = '--restore_gain' if restore_gain_after_separation is True else ''\n",
        "vocals_only = '--vocals_only' if Separation_mode == 'Vocals/Instrumental' else ''\n",
        "filter_vocals = '--filter_vocals' if filter_vocals_below_50hz is True else ''\n",
        "\n",
        "if Path(input).is_file():\n",
        "  file_path = input\n",
        "  Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "  !python inference.py \\\n",
        "        --input_audio \"{file_path}\" \\\n",
        "        --BSRoformer_model {BSRoformer_model} \\\n",
        "        --weight_BSRoformer {weight_BSRoformer} \\\n",
        "        --weight_Kim_MelRoformer {weight_Kim_MelRoformer} \\\n",
        "        --weight_InstVoc {weight_InstVoc} \\\n",
        "        --weight_InstHQ4 {weight_InstHQ4} \\\n",
        "        --weight_VOCFT {weight_VOCFT} \\\n",
        "        --weight_VitLarge {weight_VitLarge} \\\n",
        "        --overlap_demucs {overlap_demucs} \\\n",
        "        --overlap_VOCFT {overlap_VOCFT} \\\n",
        "        --overlap_InstHQ4 {overlap_InstHQ4} \\\n",
        "        --output_format {output_format} \\\n",
        "        --BigShifts {BigShifts} \\\n",
        "        --output_folder \"{output_folder}\" \\\n",
        "        --input_gain {input_gain} \\\n",
        "        {filter_vocals} \\\n",
        "        {restore_gain} \\\n",
        "        {vocals_only} \\\n",
        "        {use_VitLarge_} \\\n",
        "        {use_VOCFT_} \\\n",
        "        {use_InstHQ4_} \\\n",
        "        {use_InstVoc_} \\\n",
        "        {use_BSRoformer_} \\\n",
        "        {use_Kim_MelRoformer_}\n",
        "\n",
        "\n",
        "else:\n",
        "    file_paths = sorted(glob.glob(input + \"/*\"))[:]\n",
        "    input_audio_args = ' '.join([f'\"{path}\"' for path in file_paths])\n",
        "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "    !python inference.py \\\n",
        "        --input_audio {input_audio_args} \\\n",
        "        --BSRoformer_model {BSRoformer_model} \\\n",
        "        --weight_BSRoformer {weight_BSRoformer} \\\n",
        "        --weight_Kim_MelRoformer {weight_Kim_MelRoformer} \\\n",
        "        --weight_InstVoc {weight_InstVoc} \\\n",
        "        --weight_InstHQ4 {weight_InstHQ4} \\\n",
        "        --weight_VOCFT {weight_VOCFT} \\\n",
        "        --weight_VitLarge {weight_VitLarge} \\\n",
        "        --overlap_demucs {overlap_demucs} \\\n",
        "        --overlap_VOCFT {overlap_VOCFT} \\\n",
        "        --overlap_InstHQ4 {overlap_InstHQ4} \\\n",
        "        --output_format {output_format} \\\n",
        "        --BigShifts {BigShifts} \\\n",
        "        --output_folder \"{output_folder}\" \\\n",
        "        --input_gain {input_gain} \\\n",
        "        {filter_vocals} \\\n",
        "        {restore_gain} \\\n",
        "        {vocals_only} \\\n",
        "        {use_VitLarge_} \\\n",
        "        {use_VOCFT_} \\\n",
        "        {use_InstHQ4_} \\\n",
        "        {use_InstVoc_} \\\n",
        "        {use_BSRoformer_} \\\n",
        "        {use_Kim_MelRoformer_}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
